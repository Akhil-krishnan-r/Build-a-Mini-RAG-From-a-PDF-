{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c284236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF is being loaded...\n",
      "Embeddings are being created...\n",
      "\n",
      "==============================\n",
      "USER QUESTION:\n",
      "What caused the disappearance of the horse?\n",
      "\n",
      "RETRIEVED CONTEXT:\n",
      "\n",
      "--- Chunk 1 ---\n",
      " had, while standing at the window, drugged\n",
      "his curried mutton, and so deprived the stables of\n",
      "their watchman. As to the missing horse, there were\n",
      "abundant proofs in the mud which lay at the bottom\n",
      "of the fatal hollow that he had been there at the time\n",
      "of the struggle. But from that morning he has disap-\n",
      "peared, and although a large reward has been offered,\n",
      "and all the gypsies of Dartmoor are on the alert, no\n",
      "news has come of him. Finally, an analysis has shown\n",
      "that the remains of his supper lef\n",
      "\n",
      "--- Chunk 2 ---\n",
      " killed John Straker for the\n",
      "instant, and conﬁne ourselves to ﬁnding out what has\n",
      "become of the horse. Now, supposing that he broke\n",
      "away during or after the tragedy, where could he have\n",
      "gone to? The horse is a very gregarious creature. If\n",
      "left to himself his instincts would have been either to\n",
      "return to King’s Pyland or go over to Mapleton. Why\n",
      "should he run wild upon the moor? He would surely\n",
      "have been seen by now. And why should gypsies kid-\n",
      "nap him? These people always clear out when they\n",
      "hea\n",
      "\n",
      "--- Chunk 3 ---\n",
      "his ﬁrst impulse had been to lead him\n",
      "back to King’s Pyland, and how the devil had shown\n",
      "him how he could hide the horse until the race was\n",
      "over, and how he had led it back and concealed it at\n",
      "Mapleton. When I told him every detail he gave it up\n",
      "and thought only of saving his own skin.”\n",
      "“But his stables had been searched?”\n",
      "“Oh, and old horse-faker like him has many a\n",
      "dodge.”\n",
      "“But are you not afraid to leave the horse in his\n",
      "power now, since he has every interest in injuring it?”\n",
      "“My dear fellow,\n",
      "\n",
      "--- Chunk 4 ---\n",
      "k without receiving any injury from the small knife\n",
      "which Straker used in self-defence, and then the thief\n",
      "either led the horse on to some secret hiding-place,\n",
      "or else it may have bolted during the struggle, and\n",
      "be now wandering out on the moors. That is the\n",
      "case as it appears to the police, and improbable as it\n",
      "is, all other explanations are more improbable still.\n",
      "However, I shall very quickly test the matter when I\n",
      "am once upon the spot, and until then I cannot really\n",
      "see how we can get much f\n",
      "\n",
      "FINAL ANSWER:\n",
      " The context does not provide a clear cause for the horse's disappearance. However, it suggests that the horse might have bolted during or after the struggle where John Straker was drugged and killed, or the thief who stole Straker's horse could have led it to a secret hiding place. The text also mentions that the horse's instinct would be to return to King’s Pyland or go over to Mapleton, but it hasn't been seen yet. So, while the exact cause remains unclear, it seems likely that the horse either ran away during the commotion or was intentionally hidden by the thief.\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# **------------- CONFIG -----------**\n",
    "\n",
    "PDF_PATH = \"/home/sanoop/Documents/silv.pdf\"\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "TOP_K = 4\n",
    "OLLAMA_MODEL = \"mistral\"\n",
    "\n",
    "# ------------- LOAD PDF -------------\n",
    "\n",
    "\n",
    "def load_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ------------- CHUNK TEXT -------------\n",
    "\n",
    "\n",
    "def chunk_text(text, size, overlap):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + size\n",
    "        chunks.append(text[start:end])\n",
    "        start += size - overlap\n",
    "    return chunks\n",
    "\n",
    "# -------- FAISS + EMBEDDINGS -----------\n",
    "\n",
    "\n",
    "def build_faiss(chunks, model):\n",
    "    embeddings = model.encode(chunks)\n",
    "    embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# ------------- RETRIEVE -------------\n",
    "\n",
    "\n",
    "\n",
    "def retrieve(query, model, index, chunks, top_k):\n",
    "    q_emb = model.encode([query]).astype(\"float32\")\n",
    "    _, indices = index.search(q_emb, top_k)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "\n",
    "# ------------- OLLAMA LLM -------------\n",
    "\n",
    "\n",
    "def ask_ollama(question, context):\n",
    "    prompt = f\"\"\"\n",
    "Use the context below to answer the question.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "\n",
    "def run_rag(pdf_path, question):\n",
    "    print(\"PDF is being loaded...\")\n",
    "    text = load_pdf(pdf_path)\n",
    "\n",
    "    chunks = chunk_text(text, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "\n",
    "    print(\"Embeddings are being created...\")\n",
    "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    index = build_faiss(chunks, embed_model)\n",
    "\n",
    "    retrieved = retrieve(question, embed_model, index, chunks, TOP_K)\n",
    "    context = \"\\n\\n\".join(retrieved)\n",
    "\n",
    "    answer = ask_ollama(question, context)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"USER QUESTION:\")\n",
    "    print(question)\n",
    "\n",
    "    print(\"\\nRETRIEVED CONTEXT:\")\n",
    "    for i, chunk in enumerate(retrieved, 1):\n",
    "        print(f\"\\n--- Chunk {i} ---\\n{chunk}\")\n",
    "\n",
    "    print(\"\\nFINAL ANSWER:\")\n",
    "    print(answer)\n",
    "    print(\"==============================\")\n",
    "\n",
    "# ----- RUN -----\n",
    "\n",
    "\n",
    "question = \"What caused the disappearance of the horse?\"\n",
    "run_rag(PDF_PATH, question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e84f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
